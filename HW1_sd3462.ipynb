{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Shaival Dalal\n",
    "\n",
    "Student Netid: sd3462\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include aspects of the Data Science Workflow that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Consumer shopping habits are incredibly difficult to change once formed no matter how ingenius ads campaigns are. There are only a handful of events in a consumer's life that cause a change in habits and it is difficult to gain consumer's attention during these events due to competition from other companies.\n",
    "\n",
    "Goal: To identify and target pregnant consumers or expecting parents before other marketers do.\n",
    "\n",
    "Data: Data from two major sources. Internal and external. \n",
    "    Internal data about consumers contains unique guest identifiers, historical products purchases, age, marriage status, timing of purchase, coupon delivery preference, preferred brands of items (in-store),  baby shower registry etc. \n",
    "    External data contains data points generated by consumers outside Target. Such data points include preferred brands of coffee, preferred brands for everyday items (paper towel, applesauce, cereal) etc.\n",
    "\n",
    "Impact: The \"Pregnancy Prediction\" score model developed by Andrew Pole between 2002 and 2010 enabled Target to radically increase their sales for the Mom and Baby segment. Target's revenues increased from $44 billion to $67 billion between 2002 and 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int` (continuous), `int` (continuous), `string`, and `int` (category) respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10341\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l Datasets/advertising_events.csv | cut -d ' ' -f 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\r\n"
     ]
    }
   ],
   "source": [
    "!cut Datasets/advertising_events.csv -d ',' -f 1 | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3114 google.com\r\n",
      "   2092 facebook.com\r\n",
      "   1036 youtube.com\r\n",
      "   1034 yahoo.com\r\n",
      "   1022 baidu.com\r\n",
      "    513 wikipedia.org\r\n",
      "    511 amazon.com\r\n",
      "    382 qq.com\r\n",
      "    321 twitter.com\r\n",
      "    316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "!cut Datasets/advertising_events.csv -d ',' -f 3 | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!awk -F \",\" '{if($1==37) {print}}' Datasets/advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ads=pd.read_table(\"Datasets/ads_dataset.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    lstmain=[]\n",
    "    lsttemp=[]\n",
    "    for features in input_data:\n",
    "        number_nan=np.count_nonzero(input_data[features].isnull())\n",
    "        number_distinct=input_data[features].nunique()\n",
    "        describe=input_data[features].describe()[['mean','max','min','std','25%','50%','75%']].values.tolist()\n",
    "        lsttemp=[number_nan,number_distinct]+describe\n",
    "        lstmain.append(lsttemp)\n",
    "    output_data=pd.DataFrame(lstmain)\n",
    "    output_data.columns=['Number_NaN','Number_Distinct','Mean','Max','Min','Std','25%','50%','75%']\n",
    "    output_data.index=[input_data.columns]\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 67.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_NaN</th>\n",
       "      <th>Number_Distinct</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>52257</td>\n",
       "      <td>10</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Number_NaN  Number_Distinct      Mean   Max  Min       Std  25%  \\\n",
       "buy_freq       52257               10  1.240653  15.0  1.0  0.782228  1.0   \n",
       "\n",
       "          50%  75%  \n",
       "buy_freq  1.0  1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=getDfSummary(ads); result[result.Number_NaN>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? What would be an appropriate method for filling in missing values?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbuyer                0\n",
       "buy_freq               0\n",
       "visit_freq             0\n",
       "buy_interval           0\n",
       "sv_interval            0\n",
       "expected_time_buy      0\n",
       "expected_time_visit    0\n",
       "last_buy               0\n",
       "last_visit             0\n",
       "multiple_buy           0\n",
       "multiple_visit         0\n",
       "uniq_urls              0\n",
       "num_checkins           0\n",
       "y_buy                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ads[result.loc[result['Number_NaN']>0].index]\n",
    "#Analyse the results (returned by getDfSummary() function) to identify columns containing null values.\n",
    "result[result.Number_NaN>0] \n",
    "\n",
    "# Based on the results obtained from the above code, we can infer that only one column has NaN values.\n",
    "#We use the dropna() function to remove the NaN values and use the getDfSummary function to see how different values change.\n",
    "new=ads.dropna()\n",
    "getDfSummary(new)\n",
    "\n",
    "#Based on the results obtained by calling the getDfSummary function, we observe that the \"isbuyer\" column has only one distinct value which is 1\n",
    "#It is safe to assume that when 'buy_freq' is not null, 'isbuyer' is always 1.\n",
    "\n",
    "#We can check out how well these columns correlate by using the corr() function\n",
    "new.isbuyer.corr(new['buy_freq'])\n",
    "\n",
    "#Running the above command returns nan. Since we have removed all NaN values, we look at other factors resulting in this.\n",
    "#We can observe that when 'buy_freq' is not null, the field of 'isbuyer' demonstrates 0 standard deviation.\n",
    "#Due to this, the denominator of the correlation formula becomes 0 thus resulting in NaN output\n",
    "#We can check corrlation between different columns as well using the below command\n",
    "new.corr()\n",
    "\n",
    "#Apart from 'isbuyer', we can observe that 'buy_freq' demonstrates strong correlation with 'multiple_buy'\n",
    "new[['buy_freq','multiple_buy']]\n",
    "#The above code informs that for 'buy_freq'>1, 'multiple_buy' is 1\n",
    "\n",
    "#We can safely assume that when 'multiple_buy' is 0 and 'isbuyer' is 0, 'buy_freq' will be 0\n",
    "##ads.loc[(ads['isbuyer']==0) & ads['multiple_buy']<1]=0\n",
    "ads.loc[(ads['multiple_buy']<1) & (ads['isbuyer']==0),['buy_freq']]=0\n",
    "ads.isnull().sum()\n",
    "#We have elminated all NaN values by observing correlation values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number_NaN</th>\n",
       "      <th>Number_Distinct</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>Std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Number_NaN  Number_Distinct      Mean  Max  Min       Std  \\\n",
       "isbuyer                  0                2  0.042632  1.0  0.0  0.202027   \n",
       "multiple_buy             0                2  0.006357  1.0  0.0  0.079479   \n",
       "multiple_visit           0                2  0.277444  1.0  0.0  0.447742   \n",
       "y_buy                    0                2  0.004635  1.0  0.0  0.067924   \n",
       "\n",
       "                25%  50%  75%  \n",
       "isbuyer         0.0  0.0  0.0  \n",
       "multiple_buy    0.0  0.0  0.0  \n",
       "multiple_visit  0.0  0.0  1.0  \n",
       "y_buy           0.0  0.0  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=getDfSummary(ads)\n",
    "result.loc[(result.Number_Distinct==2)]\n",
    "\n",
    "#We can use Number_Distinct as an indicator of binary variables since the value of the below four variables can either be 0 or 1.\n",
    "#Number_Distinct of the below four variables is 2 and max and min is 1 and 0 respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
